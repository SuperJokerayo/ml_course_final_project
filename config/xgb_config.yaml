model:
    max_depth: 9
    max_bin: 100
    learning_rate: 0.02
    objective: reg:logistic
    booster: gbtree
    n_jobs: -1
    gamma: 0.01
    min_child_weight: 3
    subsample: 0.72
    colsample_bytree: 0.7
    random_state: 42
    eval_metric: rmse
    lambda: 1.0
    eta: 0.02
    seed: 42

trainer:
    num_boost_round: 5000
    verbose_eval: 250